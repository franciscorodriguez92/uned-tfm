%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% ESTADO DEL ARTE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Estado del arte}
\fancyhead[RE]{\textsc{CAP\'ITULO} \thechapter. Estado del arte}
\label{ch:EstadoArte}

\noindent El presente capítulo tiene como objetivo presentar al lector la detección del lenguaje machista en redes sociales. Para ello, se realizará una revisión de los trabajos más relevantes en la tarea de detección de lenguaje abusivo y machista, en los que se analizarán los orígenes de esta tarea, las soluciones técnicas y las aportaciones más relevantes.



\section{Clasificación de textos}
\label{sec:Ejemplo_seccion}

\noindent El procesamiento del lenguaje natural (\textit{``Natural Language Processing''}, NLP) tiene como objetivo fundamental el desarrollo de métodos que permitan a los computadores realizar tareas relacionadas con el lenguaje humano, como la comunicación o el procesamiento de textos.

La principal diferencia del NLP con el resto de líneas de investigación relacionadas con el análisis de datos o la inteligencia artificial es la necesidad de un conocimiento del lenguaje en todas sus aplicaciones. Elementos clave del lenguaje como la fonética, la fonología, la morfología, la sintaxis, la semántica, la pragmática y la discursiva son esenciales en cualquier técnica de procesamiento del lenguaje.

Una de las áreas más importantes de investigación relacionadas con el NLP es la clasificación de textos o documentos. De un modo general, se conoce como clasificación automática a la tarea de asignar una o varias categorías predefinidas sobre una colección de instancias a clasificar. Del mismo modo, la clasificación de textos se puede entender como aquella tarea en la que un documento o texto es etiquetado como perteneciente a un determinado conjunto. Este tipo de técnicas se utilizan para un gran número de aplicaciones:
\begin{itemize}
	\itemsep0em 
	\item Indexación para sistemas de recuperación de información
	\item Detección de \textit{spam}
	\item Identificación del lenguaje
	\item Análisis de sentimientos
	\item Organización de documentos
	\item Desambigüación del sentido de las palabras
	\item Filtrado de textos
\end{itemize}

Formalmente, el problema se define como un texto o documento $d$ que puede pertenecer a un conjunto fijo de clases $C=\{c_1,c_2,...,c_i\}$. La salida del sistema como predicción la clase $c \in C$.

Para resolver el problema de la clasificación de textos existen dos enfoques principales: uno basado en reglas y otro mediante algoritmo de clasificación supervisado.

Los sistemas basados en reglas utilizan patrones predefinidos por un experto para crear un conjunto de pautas mediante la combinación de palabras u otros atributos. En este tipo de arquitecturas, la precisión puede ser alta siempre que estas reglas estén cuidadosamente seleccionadas por un experto. Sin embargo, dichos sistemas resultan muy costosos de construir y mantener.

El aprendizaje supervisado se construye sobre un conocimiento a priori. Se debe disponer de un conjunto de documentos de ejemplo para cada una de las categorías consideradas. Después de una etapa de entrenamiento, el sistema queda ajustado de modo que, ante nuevos ejemplos, el algoritmo es capaz de clasificarlos en alguna de las clases existentes. Para este tipo de sistemas se utilizan distintos modelos de clasificadores: \textit{Naive Bayes}, \textit{Regresión logística}, \textit{SVM}, \textit{redes neuronales}, etc.

Para construir cualquier clasificador de textos o documentos es necesario seguir los siguientes pasos:

\begin{itemize}
	\itemsep0em 
	\item Extraer los atributos o \textit{features} necesarias para realizar una representación fiel del texto y que permita la utilización de un algoritmo de clasificación
	\item Desarrollar procedimientos por los cuales los documentos puedan ser clasificados automáticamente dentro de
	categorías.
	\item Evaluar la calidad de la clasificación en relación a algún criterio.
\end{itemize}


\subsection{Representación textual}
\label{sec:Ejemplo_subSeccion} 

\noindent La representación del texto es un paso fundamental para el procesamiento automático de textos. Una representación fiel al contenido del documento, que incluya la información necesaria para extraer conocimiento útil, será clave para el desarrollo de una arquitectura con un rendimiento adecuado. En este proceso, se han de tener en cuenta las especificaciones de los algoritmos que se empleen a continuación.

En esta fase, se definen todos los atributos utilizados en el paso posterior por el algoritmo de clasificación. Los atributos seleccionados o generados a partir de los originales serán los que marquen el éxito de la arquitectura completa. La elección del algoritmo de clasificación para los pasos posteriores influirá de un modo mucho menos significativo. Por ejemplo, en \cite{Victor2018} y \cite{Wahyu2018} se utiliza el mismo algoritmo de clasificación pero los resultados son muy diferentes debido a los atributos utilizados. 

Un modelo de representación muy utilizado se conoce como modelo de representación vectorial. Mediante esta representación, los documentos se modelan como vectores dentro de un espacio euclídeo. De este modo, se pueden aplicar operaciones de distancia entre vectores, como indicador de su cercanía según el contenido textual. En la siguiente imagen se muestra un ejemplo en dos dimensiones:

\begin{center}
	\includegraphics[width=0.4\textwidth]{imagenes/modelo_vectorial.png} %[width=4cm,,keepaspectratio]
	\captionof{figure}{Representación vector de documentos}	
\end{center}

En este caso, se tendría un vocabulario con únicamente dos rasgos $w_1$ y $w_2$ que conforman el espacio en el que se encuentran los documentos o textos $d_1$ y $d_2$. De este modo, se pueden emplear medidas de distancia, como la distancia euclídea o la distancia coseno, para comparar ambos documentos.

Utilizando este modelo, un texto quedará representado como una combinación lineal de vectores, donde cada coeficiente representa la relevancia de cada rasgo en el contenido del texto, calculado con una función de pesado. Para un texto $d$, un vocabulario de tamaño $n$: $\vec{d}=t_1j \vec{t_1} + ... + t_nj \vec{t_n} $. Para el cálculo de la relevancia de cada rasgo $t_nj$, se utilizará una función de pesado. Una de las más utilizadas se conoce como TF-IDF (frecuencia del termino x frecuencia inversa del documento) y se calcularía del siguiente modo: \[TF-IDF(\vec{t_i},\vec{d_j})=f_{ij}\log(\frac{N}{d_f(\vec{t_i})})\] donde $N$ es la dimensión del corpus (en este caso número de tweets), $f_{ij}$ la frecuencia del término en el documento y $d_f(\vec{t_i})$ el número de documentos (en este caso el tweet) en los que aparece el término.

\subsection{Clasificación}
\label{sec:Ejemplo_subSeccion} 
\noindent Como ya se introdujo en apartados anteriores, la clasificación automática de documentos se puede entender como aquella tarea en la que un documento, o una parte del mismo, es etiquetado como perteneciente a un determinado conjunto, grupo o categoría predeterminada.

Los métodos de clasificación supervisados utilizan un conjunto de documentos de ejemplo para cada una de las categorías que presenta la variable objetivo (a clasificar). Estos algoritmos, realizan una etapa de entrenamiento donde se presentan los patrones de ejemplo de modo que ante futuros patrones, el algoritmo será capaz de clasificar en alguna de las clases contenidas en el conjunto de ejemplo. Dentro de este proceso, existen muchas variables que influirán en los resultados del sistema como el tamaño del conjunto de ejemplo, la elección del algoritmo de clasificación o los parámetros de inicialización del mismo.

Existen numerosos tipos de algoritmos de clasificación, a continuación se indican los más importantes para clasificación textual:\todo{Se puede ampliar explicación de cada método o hacer nuevos apartados si fuera necesario}
\begin{itemize}
	\itemsep0em 
	\item Naive Bayes: Está basado en la teoría de la decisión de Bayes: la teoría de las probabilidades condicionadas. Por tanto, el problema de la clasificación se reduce al cálculo de las probabilidades a posteriori de una clase dado un documento.
	\item Arboles de decisión: Se trata de un método que a través de un proceso recursivo de las los atributos de entrada, realiza una representación para clasificar el conjunto de datos presentado.
	\item Máquinas de vectores de soporte (``Support Vector Machine'', SVM): Estos algoritmos pretenden encontrar una hipersuperficie de separación entre clases dentro del espacio de representación.
	\item Redes Neuronales: Son un modelo computacional compuesto por elementos ("neuronas") interconectados entre sí que aplican una transformación a los datos para producir una salida. Es posible entrenar una red neuronal para que dada una entrada determinada (un vector de representación) produzca una salida deseada (la categoría a la que corresponde ese documento).
	\item KNN (K-Nearest Neighbour): Este algoritmo se basa en la aplicación de una métrica que establezca la similitud entre un documento que se quiere clasificar y cada uno de los documentos de entrenamiento. La clase o categoría que se asigna al documento sería la categoría del documento más cercano según la métrica establecida.
\end{itemize}

%Random forest (Breiman, 2001) is an ensemble of unpruned classification or regression trees, induced from
%bootstrap samples of the training data, using random feature selection in the tree induction process. Prediction is made by aggregating (majority vote for classification or averaging for regression) the predictions of
%the ensemble. Random forest generally exhibits a substantial performance improvement over the single tree
%classifier such as CART and C4.5. It yields generalization error rate that compares favorably to Adaboost,
%yet is more robust to noise. However, similar to most classifiers, RF can also suffer from the curse of learning from an extremely imbalanced training data set. As it is constructed to minimize the overall error rate, it
%will tend to focus more on the prediction accuracy of the majority class, which often results in poor accuracy
%for the minority class. To alleviate the problem, we propose two solutions: balanced random forest (BRF)
%and weighted random forest (WRF).

\section{Detección de lenguaje o discurso del odio (\textbf{\textit{hate speech detection}}) }
\label{sec:Ejemplo_seccion}
La detección del lenguaje machista o sexista está muy relacionada con la detección del lenguaje o discurso del odio en redes sociales. Existen numerosos trabajos donde se intenta detectar distintos tipos de lenguaje del odio, entre ellos el sexismo \cite{WATANABE2018,WaseemHovy2016,Georgios2018,Badjatiya2017,Zimmerman2018,Park2017,Waseem2016}. El lenguaje del odio se refiere al uso de lenguaje agresivo, violento u ofensivo hacia un grupo específico de personas que comparten una propiedad en común, sea esta propiedad su género, su raza, sus creencias o su religión \cite{Davidson2017}. Atendiendo a esta definición, se puede considerar la detección del machismo como un caso particular del discurso del odio. Por ello, es muy interesante realizar una evaluación de los trabajos realizados en esta línea de investigación.

La detección del lenguaje del odio es una linea de investigación muy actual, datando el primer estudio evaluado en el año 2012 \cite{Xiang2012}. En este articulo se emplea un modelo de detección de temas o categorías (\textit{topic modelling}) que explota la concurrencia de palabras para la creación de atributos o \textit{features} que alimentarán un algoritmo de clasificación de aprendizaje de máquina o \textit{machine learning}. En la mayoría de trabajos previos se empleaban soluciones basadas en patrones para la clasificación de tweets. Utilizando estos métodos, el uso de expresiones coloquiales y soeces en redes sociales hace más complicado establecer las fronteras entre el uso de lenguaje ofensivo que no tiene como objetivo despreciar a ningún grupo de personas y el lenguaje del odio \cite{Davidson2017}.De este modo, este artículo supone un paso muy importante hacia la automatización y a los sistemas basados en algoritmos de \textit{machine learning}.

Durante los últimos tres años, se han sucedido diferentes artículos en la temática aumentando considerablemente la producción científica en este campo. En \cite{WaseemHovy2016} se aporta el primer corpus de referencia anotado que se utilizará posteriormente en \cite{Waseem2016,Georgios2018,Badjatiya2017,Zimmerman2018,Park2017}. Está compuesto por 16.000 \textit{tweets} etiquetados en mensajes sexistas, racistas o sin contenido ofensivo. En este primer trabajo, se sientan las bases de las soluciones aplicadas en el resto de artículos, se utilizan atributos como los \textit{unigramas, bigramas, trigramas} y \textit{cuatri-gramas} y un algoritmo de regresión logística para la clasificación.

En el artículo desarrollado por el mismo autor \cite{Waseem2016} se propone una solución similar pero se amplía el corpus en 4033 \textit{tweets} y se utiliza una plataforma de \textit{crowdsourcing} para anotar los mensajes, lo que introduce más diversidad en los criterios del etiquetado. Según los autores, el empeoramiento de los resultados puede deberse al posible sesgo que se produce en \cite{WaseemHovy2016} ya que los \textit{tweets} solo fueron etiquetados por los autores únicamente.

En el resto de artículos que evalúan su propuesta utilizando el corpus desarrollado por \cite{Waseem2016}, se utilizan redes neuronales en la etapa de clasificación y, en algunos, en la etapa de preprocesamiento. En la solución propuesta por \cite{Zimmerman2018} se aplican redes neuronales convolucionales (\textit{CNN, Convolutional Neural Network}) para codificar el texto y extraer los atributos que se utilizarán para el clasificador final, basado también en CNNs. Esta técnica permite tener en cuenta la posición de la palabra (su contexto) para extraer los atributos de cada \textit{tweet}. Esta misma idea junto con el uso de redes neuronales recurrentes (\textit{RNN, Recurrent Neural Network}) se utiliza en \cite{Badjatiya2017} para obtener los atributos en la etapa de procesamiento. En ambos artículos se consiguen mejorar los resultados alcanzados por \cite{Waseem2016} lo que afianza el uso de técnicas basadas en redes neuronales en el procesado del lenguaje.

Una idea interesante es el uso de atributos como la tendencia al racismo o al sexismo sirviéndose del historial de los usuarios. En \cite{Georgios2018} se demuestra como el uso de este tipo de atributos mejora notablemente los resultados. Esta misma idea se utiliza en \cite{Chatzakouy2017} donde se detectan cuentas agresivas estudiando al usuario y su red de seguidores.

En todos los artículos revisados anteriormente, se trata el problema como una clasificación múltiple donde el texto se puede clasificar según las etiquetas racismo, sexismo o ninguno. Sin embargo, se podría resolver el problema con un doble clasificador, el primero detecta si el texto contiene lenguaje abusivo o no y el segundo realizaría la tarea de clasificar en contenido sexista o racista \cite{Park2017}.

Un desafío importante en la detección del lenguaje del odio en redes sociales es la separación entre el lenguaje ofensivo y el lenguaje que incita o promueve el odio. Davidson \cite{Davidson2017} aporta un corpus etiquetado de 25.000 \textit{tweets} para diferenciar entre estos 2 tipos de lenguaje. En su trabajo, se propone un modelo similar a \cite{Waseem2016} donde se ponen de manifiesto las dificultades de esta solución para considerar el contexto de las palabras. De este modo, si se utilizan palabras que pueden expresar odio (por ejemplo, "\textit{gay}") en un contexto positivo, hay muchas probabilidades de que el sistema detecte odio en el texto. Los resultados serán mejorados posteriormente en \cite{WATANABE2018} donde se ampliará el número de\textit{features} y se utilizará un algoritmo basado en árboles de decisión para la tarea de clasificación.


\section{Detección de la misoginia}
\label{sec:Ejemplo_seccion}
La misoginia se define según la RAE como \textit{``Aversión a las mujeres''} \cite{MisoginiaRAE}. El machismo, sin embargo, se define como ``Actitud de prepotencia de los varones respecto de las mujeres'' o ``forma de sexismo caracterizada por la prevalencia del varón'' \cite{MachismoRAE}. Si bien estos dos términos tienen matices distintos, tienen como denominador común la discriminación de las mujeres debido a su sexo. De hecho, existen trabajos donde se expone que la misoginia se manifiesta lingüísticamente mediante la exclusión, discriminación, hostilidad, trato de violencia objetificación o cosificación sexual \cite{Anzovino2018,Fersini2018}. Muchas de estas señales textuales de misoginia serían aplicables del mismo modo al machismo \cite{Garazi2014,Giraldo1972}. 

Durante este último año, se ha llevado a cabo la competición IberEval 2018 donde una de las tareas era la detección automática de la misoginia \cite{AMI2018} (AMI, \textit{``Automatic Misogyny Identification''}). En esta tarea se propone la labor de identificar la misoginia en \textit{tweets} en español e inglés. En total, participaron once equipos de cinco países distintos para la detección en inglés, mientras que para la detección en castellano participaron un total de ocho equipos \cite{AMIOverview2018}. Los artículos publicados para esta tarea en castellano resultan de gran interés, pues guarda una relación importante con el presente trabajo.

Para la tarea de clasificación, la mayoría de los equipos utilizaron Máquinas de Vectores de Soporte (SVM, \textit{Suppor Vector Machines}) y métodos combinados de aprendizaje (EoC, \textit{Ensemble of Classifiers}). Las técnicas basadas en SVMs fueron utilizadas por \cite{Canos2018,Wahyu2018,Victor2018}. Los equipos \cite{Ahluwalia2018,Shushkevich2018,Frenda2018,Liu2018} aplicaron técnicas EoC, mientras que en \cite{Goenaga2018} se exploraron soluciones basadas en redes neuronales.

Las soluciones aportadas por \cite{Canos2018,Wahyu2018} obtuvieron la mejor tasa de acierto para la detección de la misoginia en castellano. El modelo propuesto por \cite{Canos2018} utiliza \textit{features} basadas en la vectorización de cada tweet, utilizando la medida tf-idf (\textit{term frequency - Inverse document frequency}). Posteriormente, se emplea un modelo SVM con núcleo lineal para la etapa de clasificación. Esta solución tan sencilla alcanza los mejores resultados para \textit{tweets} en castellano, pero empeora considerablemente para \textit{tweets} en inglés.

Una idea interesante, explorada en \cite{Wahyu2018}, es el uso de un léxico auxiliar que contenga palabras que se encuentren con frecuencia en textos sexistas. Este léxico fue desarrollado en un trabajo italiano \cite{Mauro2016}. En dicho estudio, se utiliza como clasificador un modelo basado en SVM con núcleo lineal para el castellano y núcleo radial para el inglés. En este caso, se alcanza la máxima tasa de acierto en inglés y en español.

\subsection{Corpus disponibles}
\label{sec:Ejemplo_subSeccion} 
A continuación se citan algunos corpus que pueden ser utilizados para la detección de lenguaje del odio en textos:
\begin{itemize}
	\itemsep0em 
	\item IberEval 2018 Automatic Misogyny Identification \cite{AMIOverview2018}: Se trata de un corpus etiquetado que contiene campos que denotan si el texto contenido en un tweet tiene un componente sexista. Fue recogido entre el 20-07-2018 y 30-11-2017 donde se recogieron 83 millones de tweets en inglés y 72 millones en castellano. Para el proceso de etiquetado se utilizadon dos pasos: en el primero dos anotadores etiquetaban el conjunto y en el segundo se utilizó una plataforma de crowdsourcing. Finalmente, se etiquetaron 3521 tweets en inglés y 3307 en español para la fase de entrenamiento. En cuanto al conjunto de test, se compartieron 831 tweets en español y 726 en inglés.
	\item Corpus etiquetado \cite{WaseemHovy2016}: Está compuesto por 16.000 \textit{tweets} etiquetados para mensajes sexistas, racistas o sin contenido ofensivo. 
\end{itemize}
 

\subsection{Ejemplo subsección}
\label{sec:Ejemplo_subSeccion} 