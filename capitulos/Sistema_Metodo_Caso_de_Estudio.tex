%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Sistema de clasificación automático
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Sistema propuesto}
\fancyhead[RE]{\textsc{CAPÍTULO} \thechapter. Sistema}
\label{ch:Sistema_Metodo_Caso_de_Estudio}

\noindent En el presente capítulo se describe el sistema automático de detección del machismo en redes sociales desarrollado en el presente trabajo fin de máster. El sistema está basado en aprendizaje supervisado y emplea distintos atributos unificados para, posteriormente, hacer uso de un algoritmo de aprendizaje de máquina que clasificará los registros de entrada en tres categorías: MACHISTA, NO\_MACHISTA Y DUDOSO. De este modo, los mensajes de texto o tweets de entrada se clasificarán según el grado de machismo que presenten.

El sistema ha sido desarrollado teniendo en cuenta la naturaleza del problema tratado. En este caso, como ya se introdujo, se trata de texto en español, por lo que el método de clasificación estará preparado para trabajar con este idioma. No obstante, la arquitectura del sistema y las técnicas aplicadas pueden ser adaptadas perfectamente para otros idiomas.

El sistema propuesto se divide en tres fases principales, tal y como se puede observar en la figura 5.1.

\begin{center}
	\includegraphics[scale=0.45,keepaspectratio]{imagenes/Pipeline_diagrama.jpg} %[width=4cm,,keepaspectratio]
    \captionof{figure}{Arquitectura clasificador}
	
\end{center}

En la primera etapa, se realiza un preprocesado diferenciado según el tipo de atributo. En este sistema, se consideran tres tipos de atributos distintos: variables categóricas (aquellas que solo pueden tomar un número discreto de valores), numéricas y texto. Para cada atributo, se aplican diferentes métodos como la tokenización, el escalado o la sustitución de emoticonos. Tras esto, se unifican los distintos tipos de atributos procesados en un conjunto de datos común que será la entrada de la última fase. En la última etapa, se emplean algoritmos de clasificación supervisada con la intención de obtener un modelo predictivo capaz de detectar textos machistas. Se emplean tres métodos distintos de aprendizaje automático en este último paso: Regresión logística, Random Forest y Máquinas de vectores de soporte (SVM, ``Support Vector Machine''). Para evaluar los resultados obtenidos con estos algoritmos, se realiza una búsqueda de parámetros de entrada (GridSearchCV) en el conjunto de entrenamiento y, posteriormente, se utilizan estos parámetros para realizar una validación cruzada en el conjunto de evaluación.


\section{Preprocesado}
\label{sec:Ejemplo_seccion}
\noindent La primera fase del sistema de clasificación lleva a cabo diferentes acciones relacionadas con el preprocesado. Se realizan tareas tan importantes como la división del texto en tokens, que permitirá que la información lingüística sea tratada por las sucesivas etapas del sistema de clasificación. Como se introdujo, el tipo de preprocesado depende del tipo de atributo considerado. 

\subsection{Texto}{}
\label{sec:Ejemplo_seccion}
\noindent El atributo que contiene el texto del tweet es el más importante para la realización del sistema automático de detección del machismo. Idealmente, se debería encontrar en este atributo todas las señales necesarias que indican si el mensaje es machista o no. Para este atributo, se aplican tres métodos distintos: preprocesado, tokenizador y creación de atributos tf-idf. En el método de preprocesado, se llevan a cabo las siguientes acciones:

\begin{itemize}
	\itemsep0em 
	\item Reemplazo de emojis: Se reemplazan los emojis por una descripción de lo que representa el dibujo. En este caso, resulta útil poder identificar el emoji que se está utilizando, ya que puede modificar el significado de la frase. Por ejemplo, en la frase de la figura 5.2 se puede observar cómo el emoji permite identificar como machista la expresión:
\begin{center}
	\includegraphics[scale=0.4,keepaspectratio]{imagenes/emoji_machista.png} %[width=4cm,,keepaspectratio]
	\captionof{figure}{Uso de emoji en contexto machista}	
\end{center}	
	\item Filtrado de URLs: Se reemplazan las URLs por la palabra ``\textit{twurl}".
	\item Reemplazo de acentos: Se eliminan los acentos propios del castellano.
	\item Filtrado de usuarios: Se reemplazan las menciones de los usuarios (las palabras que comienzan por "@") por la palabra ``\textit{twuser}". De este modo, se identifica cuando se utilizan las menciones omitiendo el usuario concreto.
	\item Convertidor de hastags: Se realiza una conversión para los \textit{hastags} que utilizan las mayúsculas como separador. Por ejemplo, la frase ``\textit{\#FelizDía}" se convertiría a ``\textit{Feliz Día}".
	\item Filtrado de hastags: Se reemplazan los \textit{hastags} (las palabras que comienzan por ``\#") por la palabra ``\textit{twhastag}".
	\item Convertidor a minúsculas: Se convierten todos los caracteres a minúscula.
	\item Reemplazo de exclamaciones: Se reemplazan los signos de exclamación por la palabra ``\textit{twexclamation}".
	\item Reemplazo de interrogaciones: Se reemplazan los signos de interrogación por la palabra ``\textit{twinterrogation}".
	\item Reemplazo de signos de puntuación: Se eliminan los signos de puntuación.

\end{itemize}

Para ilustrar el funcionamiento de la etapa de preprocesado, se supone el siguiente mensaje:
\begin{center}
	\includegraphics[scale=0.5,keepaspectratio]{imagenes/ejemplo_preprocesado_correccion.png} %[width=4cm,,keepaspectratio]
	\captionof{figure}{Ejemplo de preprocesado}	
	\label{fig:ejemplo_prep}
\end{center}

Utilizando el preprocesado se obtendría la siguiente oración transformada: ``\textit{esta es la reina de las feministas de verdad o no twinterrogation twuser thumbs\_up twurl}". Como se puede observar, se han convertido los caracteres a minúscula, se ha reemplazado el caracter de interrogación, se ha sustituido la mención del usuario, se reemplaza el emoji por una descripción y se reemplaza la URL.

A partir del texto preprocesado, se realiza la tokenización de cada mensaje. Para llevar a cabo este proceso se utiliza la clase ``\textit{TweetTokenizer}'' disponible en la librería NLTK. Se trata de un tokenizador desarrollado específicamente para el texto generado en Twitter. Tras la tokenización, se obtiene para cada mensaje una lista de unidades independientes que, mayoritariamente, representarán palabras, emoticonos y signos de puntuación.

Una vez realizada la tokenización del mensaje, se llevan a cabo tres procesos: filtrado de stopwords, reemplazo de abreviaturas y \textit{stemming}. Las palabras vacías o stopwords constituyen el grupo de palabras sin un significado concreto, por ejemplo, artículos, preposiciones o conjunciones. Este tipo de elementos no aportan información adicional al contexto del mensaje y, por tanto, se eliminan antes del proceso de clasificación.

La tarea llevada a cabo en este trabajo presenta una dificultad añadida por el entorno en el que se utiliza el lenguaje. En las redes sociales, y en Twitter en concreto, se publican mensajes cortos y, frecuentemente, no siguen las reglas convencionales del idioma. De este modo, el uso de abreviaturas o emoticonos está muy extendido en este tipo de plataformas. Es por ello, que realizar diccionarios específicos para cada idioma que permitan normalizar este tipo de contenido es muy importante previo a la tarea de clasificación. En este trabajo, se utiliza el diccionario en castellano realizado en \cite{Helena2016} que compila diccionarios de palabras ``slang'', abreviaturas, contracciones y emoticonos que ayudan al preprocesamiento de textos publicados en redes sociales. Un ejemplo del tipo de expresiones que se reemplazan en este proceso se podría ilustrar del siguiente modo: ``\textit{Esta es aki la reina de las feministas de verdad o no?}''. En el ejemplo anterior, se encuentra la palabra coloquial ``aki'' que normalizada al español sería ``aquí''.

Por último, se aplica un método de stemming para reducir las palabras a su raíz. En este caso, se utiliza el algoritmo de Porter \cite{Porter1980} desarrollado en la década de los ochenta por Martin Porter y basado en un conjunto de reglas aplicadas en cascada para obtener la raíz de las palabras.

Para ilustrar el proceso anterior, se supone el ejemplo de la figura \ref{fig:ejemplo_prep}. Aplicando el proceso de tokenización se obtendría la siguiente lista de tokens: ['reina', 'feminista', 'verdad', 'twinterrog', 'twuser', 'thumbs\_up', 'twurl']. Como se puede observar, se obtiene una lista de palabras, emoticonos y signos de interrogación entre los cuales no se encuentran las palabras vacías.

A partir del texto tokenizado, es necesario representar la información contenida en el texto de un modo interpretable por las etapas posteriores del sistema de clasificación. Para el presente trabajo, se realiza esta representación utilizando vectores de términos \textit{tf-idf} mediante los unigramas de los tokens obtenidos del proceso anterior. Los unigramas considerados serán aquellos que se repitan en, al menos, un 1\% en los documentos del corpus. Se han realizado pruebas para distintos filtros de frecuencia, reduciendo el umbral hasta el 0.3\%, sin embargo, los mejores resultados se han obtenido para un 1\% de frecuencia.


\subsection{Atributos numéricos}{}
\label{sec:Ejemplo_seccion}
\noindent Otro tipo de atributos que se utiliza en el presente sistema son los numéricos. En este caso particular, se consideran los siguientes atributos numéricos:

\begin{itemize}
	\itemsep0em 
	\item display\_text\_width: número de caracteres del tweet. 
	\item favorite\_count: número de veces que el tweet ha sido marcado como favorito.
	\item retweet\_count: número de veces que el tweet ha sido retwiteado.
	\item followers\_count: número de seguidores del usuario que publica el tweet.
	\item friends\_count: número de personas seguidas por el usuario que publica el tweet.
	\item listed\_count: número de listas en las que está inscrito el usuario que publica el tweet.
	\item statuses\_count: número de tweets publicados por el usuario que publicó el tweet.
	\item favourites\_count: número de tweets que el usuario que publicó el tweet marcó como favoritos.
\end{itemize}

El uso de este tipo de atributos permite tener en cuenta distintos aspectos del contexto en el que se genera el tweet. Por ejemplo, existe un grupo de atributos como favorite\_count o retweet\_count que mide la popularidad del tweet. Este tipo de atributos permite valorar la posible propagación de un mensaje machista en Twitter. Por otra parte, existen campos como followers\_count que miden la popularidad del usuario que publica el tweet. Además, otros campos como display\_text\_width demuestran tener una relevancia especial para los tweets etiquetados con categoría ``DUDOSO'' (figura 4.9).

En los atributos numéricos se realizan únicamente dos procesos: imputación de valores nulos y escalado. En este caso, se imputan los valores nulos sustituyéndolos por 0 y, para el escalado, se realiza una estandarización para que en los valores numéricos se consiga una media nula y una desviación estándar de uno.


\subsection{Atributos categóricos}{}
\label{sec:Ejemplo_seccion}

\noindent El último tipo de atributos que se emplea son los atributos categóricos. Para este sistema, se consideran los siguientes atributos categóricos:

\begin{itemize}
	\itemsep0em 
	\item source: tipo de dispositivo con el que se publica el tweet. 
	\item respuesta: indica si el tweet es una respuesta a otro.
	\item respuesta\_screen\_name: nombre del usuario al que se responde.
	\item hastag\_presence: indica la presencia de ``hastags'' en el tweet.
	\item url\_presence: indica la presencia de URLs en el tweet.
	\item media\_type: indica si el tweet contiene imagenes o videos.
	\item mentions\_presence: indica la presencia de la mención a algún usuario en el tweet.
	\item verified: indica si el usuario que publica el tweet es verificado por Twitter.
\end{itemize}

Al igual que en el caso de los atributos numéricos, el uso de algunos de estos atributos categóricos intenta recoger el contexto en el que se publica el mensaje. Por ejemplo, el campo ``verified'' mide la influencia del usuario y los atributos ``url\_presence'' o ``media\_type'' indican si el mensaje comparte otro contenido distinto a su texto.

En los atributos categóricos únicamente se aplica una transformación para convertir esta información a tipo numérico y que sea posible utilizarlo en el posterior algoritmo de clasificación. En este caso, se emplea la codificación ``one-hot'' que crea un nuevo atributo por cada valor del atributo categórico asignando 1 ó 0 según la existencia o no de ese valor para cada registro.

\section{Unión de atributos}
\label{sec:Ejemplo_seccion}
\noindent En la segunda fase del sistema, se combinan todos los atributos que han sido preprocesados en la etapa anterior. Para cada tipo de atributo, se ha descrito el procesamiento realizado con la idea de acondicionar el conjunto de datos que se utilizará para ajustar un modelo de aprendizaje supervisado.

En esta etapa se concatenan los tres tipos distintos de atributos que se consideran:

\begin{itemize}
	\itemsep0em 
	\item texto: contiene los atributos tf-idf extraídos del texto preprocesado.
	\item numéricos: se incorporan todos los atributos numéricos considerados habiendo realizado previamente un proceso de estandarización.
	\item categóricos: se incorporan todos los atributos categóricos considerados habiendo realizado una transformación de sus valores a atributos numéricos.
\end{itemize}

La salida de esta etapa será un conjunto de datos que contendrán los tres tipos de atributos descritos y serán la entrada de la última fase del sistema.

\section{Clasificación}
\label{sec:Ejemplo_seccion}
\noindent La última etapa del sistema realiza el ajuste de un algoritmo de aprendizaje de máquina a los datos obtenidos en las fases anteriores.

El objetivo final del presente trabajo es la detección del lenguaje machista en las redes sociales. Este problema se puede modelar como una clasificación de documentos en la que se asignará una categoría a cada uno de los mensajes que conforman el corpus. 

En la actualidad, la mayoría de trabajos llevan a cabo esta tarea mediante algoritmos o ténicas de aprendizaje supervisado \cite{Zimmerman2018,Davidson2017,AMIOverview2018}. Para la tarea de clasificación se emplean tres algoritmos distintos disponibles en ``scikit-learn'': Regresión logística, Random Forest y SVM. Para todos ellos, se realiza una búsqueda de parámetros óptimos para distintas configuraciones teniendo en cuenta el tiempo de computación de esta búsqueda:

\begin{itemize}
	\itemsep0em 
	\item Línea base 1: Se clasifican todos los registros de evaluación con la categoria mayoritaria.
	\item Línea base 2 (atributos de texto): Se aplica regresión logística con la siguiente búsqueda de parámetros C = [1, 10], ``class\_weight'' = [None, 'balanced']. El parámetro C permite ajustar la regularización (valores más pequeños indican una mayor regularización) mientras que ``class\_weight'' realiza un balanceo de los valores de la clase cuando se configura el valor ``balanced''.
	\item Regresión logística (atributos numéricos, categóricos y texto): Se aplica una regresión logística a todos los atributos disponibles con la siguiente búsqueda de parametros: C = [1, 10], ``class\_weight'' = [None, 'balanced'].
	\item Random Forest (atributos numéricos, categóricos y texto): Se utiliza el algoritmo Random Forest con todos los atributos disponibles y los siguientes parámetros: ``n\_estimators'' = [250, 450], ``bootstrap'' = (True, False), ``max\_depth''= [None, 30]. El parámetro ``n\_estimators'' permite establecer el número de arboles de decisión a utilizar, ``bootstrap'' permite indicar si todo el conjunto de datos debe de ser utilizado para entrenar cada árbol y ``max\_depth'' indica la profundidad máxima de cada árbol.
	\item SVM (atributos numéricos, categóricos y texto): Se utiliza el algoritmo SVM con todos los atributos disponibles y los siguientes parámetros: C = [1, 10, 100, 10000], ``gamma'' = [0.001, 0.1, 0.6, ``auto''], ``kernel'' = 'rbf'. El parámetro C permite regular el margen de la frontera de decisión mientras que ``kernel'' hace referencia al tipo de núcleo utilizado. En este caso, se utiliza un núcleo gaussiano donde la influencia de cada vector de soporte individualmente se regula con el parámetro ``gamma''.
\end{itemize}

Se ha seleccionado un subconjunto muy reducido de valores distintos para la búsqueda de parámetros en cada configuración debido a las limitaciones computacionales.

