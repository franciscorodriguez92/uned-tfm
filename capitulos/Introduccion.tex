%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% INTRODUCCION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introducción}
\fancyhead[RE]{\textsc{CAPÍTULO} \thechapter. Introducción}
\label{ch:Introduccion}
\pagenumbering{arabic}

\noindent El presente capítulo tiene como objetivo presentar al lector la motivación y los objetivos del presente trabajo. Además, se indica la estructura y los principales puntos abordados en el trabajo fin de máster. 

\section{Motivación}
\label{sec:Motivacion}

\noindent Con el rápido crecimiento de las redes sociales, la comunicación entre personas de diferentes culturas en todo el mundo se produce de forma mucho más directa y sencilla. Esto provoca un gran aumento de ``ciber'' conflictos entre las personas que utilizan con frecuencia este tipo de plataformas. Con millones de contribuciones generadas diariamente por los usuarios de este tipo de herramientas, resulta impracticable y poco escalable implementar una política manual para detectar prácticas como el machismo o la xenofobia. Pese a esto, empresas como Facebook han anunciado planes para contratar varios miles de empleados encargados de moderar el contenido de la plataforma \cite{FacebookHiring2017}. Pese a dedicar muchos esfuerzos y recursos, las grandes compañías como Twitter encuentran gran cantidad de dificultades para afrontar el problema \cite{Twitter2016} debido a la gran cantidad de posts que no pueden ser mediados por sus moderadores. Además, han impulsado fuertes iniciativas para responder a las críticas recibidas por no atajar el problema con la suficiente contundencia. Twitter, por ejemplo, ha aplicado políticas para prohibir el uso de sus plataformas a quienes ataquen a personas o grupos sociales \cite{TwitterPolicy}. La importancia de este problema junto con la gran cantidad de información generada por los usuarios hace necesaria la creación de sistemas y herramientas que puedan automáticamente detectar el contenido inapropiado en redes sociales.

Un nuevo estudio realizado en EEUU \cite{Duggan2017} sostiene que el 41\% de personas encuestadas había sufrido personalmente algún tipo de discriminación o acoso online, de las cuales el 18\% había sufrido algún tipo de acoso grave, por ejemplo debido a su género (8\%). De igual modo, las mujeres tienen más de el doble de probabilidades de sufrir acoso debido a su género \cite{Duggan2017}.

El problema es aún más grave si se tiene en cuenta que un abuso verbal en redes sociales puede acarrear un acto de violencia física. No solo es importante por el propio mensaje, este tipo de plataformas permiten propagar un mensaje machista que incita al odio, al menosprecio o a la desigualdad. De hecho, no es inusual que contenidos machistas hacia las mujeres sean trasladados a acciones violentas. Por ejemplo, algunos estudios sociales como \cite{Fulper2014} demuestra la existencia de una correlación entre el número de violaciones y el número de tweets machistas por estado en USA. Esto sugiere que las redes sociales pueden ser utilizadas como detector de violencia machista e incluso pueden ayudar a anticiparla o prevenirla.

Amnistía internacional publicó recientemente un estudio donde denuncia este hecho \cite{Amnesty2017}. En el reporte, se explica cómo para muchas mujeres Twitter es una plataforma donde la violencia y al abuso contra ellas florece, en la mayoría de los casos, sin ninguna consecuencia. Según este informe, Twitter está fallando como empresa a la hora de respetar los derechos de la mujer en línea. En lugar de reforzar las voces de las mujeres, la violencia y el abuso que experimentan en la plataforma hace que las mujeres se autocensuren a la hora de postear, limiten sus interacciones e incluso les hace abandonar Twitter por completo. De este modo, la violencia y el abuso que muchas mujeres experimentan en Twitter tiene un efecto perjudicial en su derecho a expresarse en igualdad, libremente y sin miedo. 

Todo lo expuesto justifica, sin duda, la realización de este trabajo, en el que se propone una arquitectura para la detección automática del machismo. Todos los estudios listados justifican la necesidad de detectar y filtrar de un modo automatizado el contenido que incita o promueve el machismo. En concreto, el lenguaje machista o sexista, ocupa gran parte de este discurso en sitios webs como Twitter. Mientras que en la mayoría de las plataformas el uso de este tipo de lenguaje está prohibido, el tamaño de estas redes hace imposible controlar todo el contenido que generan. Resulta adecuado, por tanto, afirmar que las posibilidades y ventajas que proporcionaría un sistema capaz de detectar este tipo de actitudes en en texto de manera automática supondrían un beneficio sustancial para los usuarios y consumidores de redes sociales e internet en general.


\section{Propuesta y objetivos}
\label{sec:PropuestaYObjetivos}

\noindent El trabajo realizado en este proyecto presenta un sistema de clasificación automático para la detección del machismo en redes sociales. El abuso online se ha convertido en un gran problema, especialmente por el anonimato y la interactividad de la web que facilita el incremento y permanencia de este tipo de abusos. Se trata de un campo en el que ha aumentado la producción científica enormemente durante este mismo año y donde se han desarrollado competiciones con gran participación por parte de la comunidad científica \cite{AMIOverview2018}.

Los atributos utilizados para la tarea de clasificación  se agrupan en 3 tipos: variables categóricas, numéricas y texto. Para cada atributo, se aplican diferentes métodos como la tokenización, el escalado o la sustitución de emoticonos. Tras esto, se unifican los distintos tipos de atributos procesados en un conjunto de datos común que será la entrada de la última fase. En la última etapa, se emplean algoritmos de clasificación supervisada con la intención de obtener un modelo predictivo capaz de detectar las señales textuales que expresan lenguaje machista. A lo largo del trabajo, se presenta el ciclo completo para la recolección de datos, preprocesamiento y construcción del sistema de clasificación para el lenguaje.

Para el correcto funcionamiento de estos sistemas de clasificación supervisados se necesitan ejemplos previamente etiquetados con los que entrenar el algoritmo. En este caso, se ha desarrollado un corpus mediante la búsqueda de 29 términos o expresiones utilizando como fuente de datos la red social Twitter. Este corpus está compuesto por 3600 mensajes y ha sido etiquetado en 3 categorías: MACHISTA, NO\_MACHISTA Y DUDOSO. De este modo, este trabajo realiza una aportación importante mediante este corpus etiquetado compuesto por un gran número de expresiones y actitudes machistas.


\section{Estructura del documento}
\label{sec:EstructuraDelDocumento}

\noindent En este capítulo se estructuran los capítulos que componen el presente trabajo fin de máster.

\begin{description}

\item \textbf{Capítulo 1. Introducción.} Este capítulo introduce los principales motivos que han llevado a la realización de este trabajo, así como la problemática y el estado actual de la disciplina. Por último, se presentan las diferentes contribuciones del trabajo realizado.
\item \textbf{Capítulo 2. Estado del arte.} Este capítulo describe en mayor detalle la disciplina que nos ocupa, presentando su origen y su historia hasta el presente. Se muestran las técnicas actuales más utilizadas para resolver las tareas más relevantes del tema abordado, así como sus debilidades.
\item \textbf{Capítulo 3. Herramientas utilizadas.}  En este capítulo se describen todas las herramientas y tecnologías que han sido necesarias para elaborar el proyecto. Se realiza una definición de cada una de ellas y se describe el papel que desempeñan dentro del trabajo desarrollado.
\item \textbf{Capítulo 4. MeTwo dataset (Machismo and Sexism Twitter Identification dataset)}  En este capítulo se describe en profundidad la metodología seguida para componer el corpus con texto y expresiones machistas.
\item \textbf{Capítulo 5. Sistema.}  En este capítulo se describe en profundidad el sistema de clasificación propuesto.
\item \textbf{Capítulo 6. Evaluación y discusión.} Este capítulo describe la metodología utilizada para evaluar la propuesta realizada, a la vez que presenta los resultados obtenidos al evaluar el método propuesto en diferentes tareas y sobre colecciones de evaluación de distintos dominios. Además, se analiza y discute en profundidad los resultados obtenidos en la evaluación presentada anteriormente.
\item \textbf{Capítulo 7. Conclusiones y trabajo futuro.} Este capítulo recopila las diferentes conclusiones extraídas del trabajo realizado, y propone algunas líneas de trabajo futuro.

\end{description}